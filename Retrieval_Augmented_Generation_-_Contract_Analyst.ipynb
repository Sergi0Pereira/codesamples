{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj7R48-ZXmTC"
      },
      "source": [
        "# Retrieval Augmented Generation - Procurement Contract Analyst -  Palm2 & LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/guruvittal/codesamples/blob/main/Retrieval_Augmented_Generation_-_Contract_Analyst.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/guruvittal/codesamples/blob/main/Retrieval_Augmented_Generation_-_Contract_Analyst.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/guruvittal/codesamples/blob/main/Retrieval_Augmented_Generation_-_Contract_Analyst.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "8OWkuMBbSvGb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPG8eRQCcNQ3"
      },
      "source": [
        "## Installation & Authentication\n",
        "\n",
        "**Install google-cloud-aiplatform & langchain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdsE3DEJcM35"
      },
      "outputs": [],
      "source": [
        "# Install langchain and related libraries\n",
        "!pip install langchain unstructured\n",
        "\n",
        "# Install Vertex AI LLM SDK\n",
        "! pip install google-cloud-aiplatform\n",
        "\n",
        "# Store docs in local vectorstore as index\n",
        "!pip install -q chromadb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwMB9pqcniz"
      },
      "source": [
        "**Authenticate**\n",
        "Within the colab a simple user authentication is adequate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HP80SWi0rIBL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lcArn48r6pZ"
      },
      "source": [
        "**Reference Libraries**\n",
        "In this section, we will identify all the library classes that will be referenced in the code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chroma DB as Vector Store Database\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Using Vertex AI\n",
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
        "\n",
        "# Using Google Cloud Storage Directory loader from langchain\n",
        "from langchain.document_loaders import GCSDirectoryLoader\n",
        "\n",
        "import time\n",
        "\n",
        "from pydantic import BaseModel, Extra, root_validator\n",
        "from typing import Any, Mapping, Optional, List, Dict\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.embeddings.base import Embeddings\n",
        "\n",
        "from langchain.embeddings import VertexAIEmbeddings"
      ],
      "metadata": {
        "id": "4NNCiu-1JEr0",
        "outputId": "4e2e5d12-84ad-4e6f-a9e6-6f97c67f84bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI SDK version: 1.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yHf4ipxYyfy"
      },
      "source": [
        "## Initiatlize Vertex AI\n",
        "\n",
        "**We will need a project id and location where the Vertex compute and embedding will be hosted**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EZe8iS2CY2E8"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"PROJECT_ID\"  # @param {type:\"string\"}\n",
        "\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI SDK\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YozENqoAmm9"
      },
      "source": [
        "## Ingest the Contracts to build the context for the LLM\n",
        "\n",
        "*Load all the Procurement Contract Documents*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td4rD2MQtM1O"
      },
      "outputs": [],
      "source": [
        "loader = GCSDirectoryLoader(project_name=PROJECT_ID, bucket=\"contractunderstandingatticusdataset\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Da7_1bpFGpb"
      },
      "source": [
        "*Split documents into chunks as needed by the token limit of the LLM and let there be an overlap between the chunks*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E_qzSuMFHKt",
        "outputId": "64235055-e8ae-4816-aa1b-7bc2a7c6c177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 2150\n"
          ]
        }
      ],
      "source": [
        "# split the documents into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(f\"# of documents = {len(docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0htdnYAHonv"
      },
      "source": [
        "## Structuring the ingested documents in a vector space using a Vector Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwJlBNwIy0y"
      },
      "source": [
        "*Create an embedding vector engine for all the text in the contract documents that have been ingested*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nNWJ6XaH1fa",
        "outputId": "c453146f-de46-4311-a7cb-526e37eac097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VertexAIEmbeddings(project=None, location='us-central1', request_parallelism=5, max_retries=6, stop=None, model_name='textembedding-gecko', client=<vertexai.preview.language_models._PreviewTextEmbeddingModel object at 0x7bbf680a4cd0>, temperature=0.0, max_output_tokens=128, top_p=0.95, top_k=40, credentials=None, n=1, streaming=False)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Embedding has a max of 600 requests per minute so we are within limits\n",
        "# https://cloud.google.com/vertex-ai/docs/quotas\n",
        "\n",
        "REQUESTS_PER_MINUTE = 590\n",
        "\n",
        "embedding = VertexAIEmbeddings(requests_per_minute=REQUESTS_PER_MINUTE)\n",
        "\n",
        "embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A6JEaReI96b"
      },
      "source": [
        "*Create a vector store and store the embeddings in the vector store*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ITiqOdEDJGOn"
      },
      "outputs": [],
      "source": [
        "contracts_vector_db = Chroma.from_documents(docs, embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVCftNbU-wp0"
      },
      "source": [
        "## Obtain handle to the retriever\n",
        "\n",
        "We will use the native retriever provided by Chroma DB to perform similarity search within the contracts document vector store among the different document chunks so as to return that document chunk which has the lowest vectoral \"distance\" with the incoming user query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Xb2VCn6e-0zp"
      },
      "outputs": [],
      "source": [
        "# Expose index to the retriever\n",
        "retriever = contracts_vector_db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\":2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcwQNvfN_6Rn"
      },
      "source": [
        "## Define a Retrieval QA Chain to use retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ElWUO3fQAMaH"
      },
      "outputs": [],
      "source": [
        "# Create chain to answer questions\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name='text-bison-32k',\n",
        "    max_output_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Uses LLM to synthesize results from the search index.\n",
        "# We use Vertex PaLM Text API for LLM\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHYlgYQhFTQW"
      },
      "source": [
        "## Leverage LLM to search from retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUZDkQOrGb9X"
      },
      "source": [
        "*Example:*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGTS8x7TFoOn",
        "outputId": "817c82e0-d909-42b0-f02e-a786529db172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'Who all entered into agreement with Sagebrush?', 'result': ' The company, the bank, and the agent entered into the agreement with Sagebrush. ', 'source_documents': [Document(page_content='Each party cooperated and participated in the drafting and preparation of this Agreement and the documents referred to herein, and any and all drafts relating thereto exchanged among the parties shall be deemed the work product of all of the parties and may not be construed against any party by reason of its drafting or preparation. Accordingly, any rule of law or any legal decision that would require interpretation of any ambiguities in this Agreement against any party that drafted or prepared it is of no application and is hereby expressly waived by each of the parties hereto, and any controversy over interpretations of this Agreement shall be decided without regards to events of drafting or preparation.\\n\\n[Signature Pages Follow]   7\\n\\nIN WITNESS WHEREOF, each of the parties hereto has executed this COOPERATION AGREEMENT or caused the same to be executed by its duly authorized representative as of the date first above written. Allison Transmission Holdings, Inc.', metadata={'source': 'gs://contractunderstandingatticusdataset/ALLISONTRANSMISSIONHOLDINGSINC_12_15_2014-EX-99.1-COOPERATION AGREEMENT.txt'}), Document(page_content=\"32\\n\\nIf the foregoing correctly sets forth the arrangement among the Company, the Bank and the Agent, please indicate acceptance thereof in the space  provided below for that purpose, whereupon this letter and the Agent's acceptance shall constitute a binding agreement.\\n\\nAccepted as of the date first above written\\n\\n33\\n\\nVery truly yours,                   ATHENS FEDERAL COMMUNITY BANK        ATHENS BANCSHARES CORPORATION           By Its Authorized Representative        By Its Authorized Representative:\\n\\nJeff Cunningham        Jeff Cunningham President and Chief Executive Officer        President and Chief Executive Officer\\n\\nKEEFE, BRUYETTE & WOODS, INC.    By its Authorized Representative\\n\\nHarold T. Hanley, III, Managing Director     Managing Director\", metadata={'source': 'gs://contractunderstandingatticusdataset/ATHENSBANCSHARESCORP_11_02_2009-EX-1.2-AGENCY AGREEMENT , 2009.txt'})]}\n"
          ]
        }
      ],
      "source": [
        "query = \"Who all entered into agreement with Sagebrush?\"\n",
        "result = qa({\"query\": query})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgYa4k1WiolM"
      },
      "source": [
        "## Build a Front End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRjBQsXqirbC"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import markdown\n",
        "\n",
        "def chatbot(inputtext):\n",
        "    result = qa({\"query\": inputtext})\n",
        "\n",
        "    return result['result'], get_public_url(result['source_documents'][0].metadata['source']), result['source_documents'][0].metadata['source']\n",
        "\n",
        "from google.cloud import storage\n",
        "\n",
        "def get_public_url(uri):\n",
        "    \"\"\"Returns the public URL for a file in Google Cloud Storage.\"\"\"\n",
        "    # Split the URI into its components\n",
        "    components = uri.split(\"/\")\n",
        "\n",
        "    # Get the bucket name\n",
        "    bucket_name = components[2]\n",
        "\n",
        "    # Get the file name\n",
        "    file_name = components[3]\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "    return blob.public_url\n",
        "\n",
        "\n",
        "print(\"Launching Gradio\")\n",
        "\n",
        "iface = gr.Interface(fn=chatbot,\n",
        "                     inputs=[gr.Textbox(label=\"Query\")],\n",
        "                     examples=[\"Who are parties to ADMA agreement\", \"What is the agreement between MICOA & Stratton Cheeseman\", \"What is the commission % that Stratton Cheeseman will get from MICOA and how much will they get if MICOA's revenues are $100\"],\n",
        "                     title=\"Contract Analyst\",\n",
        "                     outputs=[gr.Textbox(label=\"Response\"),\n",
        "                              gr.Textbox(label=\"URL\"),\n",
        "                              gr.Textbox(label=\"Cloud Storage URI\")])\n",
        "\n",
        "iface.launch()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
