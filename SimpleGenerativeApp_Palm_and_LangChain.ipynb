{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Generative App Using Palm 2 & LangChain\n",
        "\n",
        "In this simple app, we will illustrate few ways of invoking Vertex AI:\n",
        "- One using the Google API Key (obtainable through markersuite.google.com\n",
        "- One using Google Cloud after authenticating through google_auth or using service account"
      ],
      "metadata": {
        "id": "Uj7R48-ZXmTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/guruvittal/codesamples/blob/main/SimpleGenerativeApp_Palm_and_LangChain.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/guruvittal/codesamples/blob/main/SimpleGenerativeApp_Palm_and_LangChain.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/guruvittal/codesamples/main/SimpleGenerativeApp_Palm_and_LangChain.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "BgK3Mb8pcv8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation & Authentication\n",
        "\n",
        "**Install google-generativeai & langchain**"
      ],
      "metadata": {
        "id": "SPG8eRQCcNQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install langchain & Google Generative AI SDK (Usable with Makersuite end point)\n",
        "!pip install langchain google-generativeai\n",
        "\n",
        "# Install Vertex AI LLM SDK (Google Cloud Vertex AI endpoint)\n",
        "! pip install --upgrade google-cloud-aiplatform\n",
        "\n"
      ],
      "metadata": {
        "id": "IdsE3DEJcM35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authenticate through Google Cloud**"
      ],
      "metadata": {
        "id": "ptwMB9pqcniz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Authentication with Google\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "    google_auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "HP80SWi0rIBL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Vertex AI Model & Other libraries**\n",
        "\n",
        "***In this section, we will define base classes and libraries for use  "
      ],
      "metadata": {
        "id": "4lcArn48r6pZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
        "\n",
        "# Initialize Vertex AI SDK\n",
        "import vertexai\n",
        "\n",
        "from pydantic import BaseModel, root_validator\n",
        "from typing import Any, Mapping, Optional, List, Dict\n",
        "from langchain.llms.base import LLM\n",
        "from langchain.llms import VertexAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "ax6hlCt7YbXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d72e6172-90e2-44fb-dd69-5f6faad84164"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertex AI SDK version: 1.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Vertex AI"
      ],
      "metadata": {
        "id": "7yHf4ipxYyfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PROJECT_ID = \"argolis-project-340214\"  # @param {type:\"string\"}\n",
        "\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "EZe8iS2CY2E8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invoking Text Bison directly"
      ],
      "metadata": {
        "id": "-EeiGb_cnThu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = VertexAI(\n",
        "    model_name='text-bison-32k',\n",
        "    max_output_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "#Asking Text Bison the question directly\n",
        "print(\"Response for direct question: WHo was the president of US when Justin Bieber was born\")\n",
        "response = llm('WHo was the president of US when Justin Bieber was born')\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hloE0JOahc3Q",
        "outputId": "71bf1e88-9f53-499c-e68a-ebb580765ea6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response for direct question: WHo was the president of US when Justin Bieber was born\n",
            " George Walker Bush\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Invoking Text Bison Using LangChain Prompt Template"
      ],
      "metadata": {
        "id": "19iifnZ5luA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Building a Prompt Template with LangChain*"
      ],
      "metadata": {
        "id": "blSr3Ihfdw7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "Answer: Let's think step by step.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "question = \"Who was the president in the year Justin Beiber was born?\"\n",
        "print(chain.invoke({\"question\": question}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmPJuLcsq9qV",
        "outputId": "265ff2c7-409b-45e4-f23a-a9dae0730590"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Justin Bieber was born on March 1, 1994. Bill Clinton was the president of the United States from 1993 to 2001. \n",
            "The final answer is Bill Clinton\n"
          ]
        }
      ]
    }
  ]
}
